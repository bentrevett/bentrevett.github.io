{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92a5c18d-ebc9-49d2-931b-c51f8d7f7f1a",
   "metadata": {},
   "source": [
    "# Parallelism in Python\n",
    "\n",
    "Ever wondered how to speed-up your operations by performing them in parallel? Turns out it's not as complicated as you might think.\n",
    "\n",
    "First, we'll need some operations that we want to do in parallel. In this notebook, we'll uppercase each string in a list of strings. To simulate different inputs having different processing time, we'll have our function which does the uppercasing, `fn`, also sleep for as many seconds as there are characters in the string, e.g. `\"hello\"` will sleep for 5 seconds before returning `\"HELLO\"`, `\"a\"` will sleep for 1 second, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb34a086-b0e2-4c1d-89ff-345d58d87682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "tokens = [\"hello\", \"world\", \"how\", \"are\", \"you\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\"]\n",
    "\n",
    "def fn(t):\n",
    "    time.sleep(len(t))\n",
    "    return t.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3fec1-cef3-49ea-9be1-41e48a24f2c0",
   "metadata": {},
   "source": [
    "## ThreadPoolExecutor\n",
    "\n",
    "The first method of parallelism we'll look at is using *threads*. The `concurrent.futures` standard library has a `ThreadPoolExecutor` which we can use to execute a function within a thread.\n",
    "\n",
    "The `ThreadPoolExecutor` when used as a context manager can use the `map` method, which applies the function, given as the first argument, to all elements in the second argument.\n",
    "\n",
    "It returns a generator, so we explicitly convert it to a list before printing it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7668b171-5c6b-453e-bf21-d1de8490972f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HELLO', 'WORLD', 'HOW', 'ARE', 'YOU', 'A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
      "5.0064839580000005\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "t0 = time.monotonic()\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    results = executor.map(fn, tokens)\n",
    "dt = time.monotonic() - t0\n",
    "print(list(results))\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6eda4d-c780-4eab-a2a6-ef10ee8243ba",
   "metadata": {},
   "source": [
    "More explicitly, we can `submit` each element with a function to apply (useful if we want to apply a different function to each element) and then get the `result`. Each `submit` creates a thread and applies the function to the input, creating a `Future` object. We can get the actual result from the `Future` using `result`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "707c6d72-7e99-4045-bcc4-2d387af1250c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HELLO', 'WORLD', 'HOW', 'ARE', 'YOU', 'A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
      "5.007868625\n"
     ]
    }
   ],
   "source": [
    "t0 = time.monotonic()\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(fn, t) for t in tokens]\n",
    "    results = [future.result() for future in futures]\n",
    "dt = time.monotonic() - t0\n",
    "print(results)\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2902440-e27d-4cbc-af8e-3c01838922aa",
   "metadata": {},
   "source": [
    "If we didn't care about the order in which the results were returned, i.e. we don't care that the output order is not the same as the input order, then we can use `as_completed`. This will get the results as they complete. Our example has the single character strings only wait for a second, so they should complete first. The order is not deterministic though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e0c2f83-1474-4f3d-b7f0-a99c39036d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'HOW', 'ARE', 'YOU', 'HELLO', 'WORLD']\n",
      "5.009487957999999\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import as_completed\n",
    "\n",
    "t0 = time.monotonic()\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(fn, t) for t in tokens]\n",
    "    results = [future.result() for future in as_completed(futures)]\n",
    "dt = time.monotonic() - t0\n",
    "print(results)\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaa85f5-23b3-4c06-baa0-2e4dbe964e3a",
   "metadata": {},
   "source": [
    "There's also a `ProcessPoolExecutor` which has the exact same functions as the `ThreadPoolExecutor`, but creates *processes* instead of threads.\n",
    "\n",
    "However, I've found processes do not work in Jupyter Notebooks, which is apparently due to some iPython issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a4b1f5a-1038-41d1-8f8c-36943125ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "#t0 = time.monotonic()\n",
    "#with ProcessPoolExecutor() as executor:\n",
    "#    futures = [executor.submit(fn, t) for t in tokens]\n",
    "#    results = [future.result() for future in as_completed(futures)]\n",
    "#dt = time.monotonic() - t0\n",
    "#print(results)\n",
    "#print(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620ffda6-4dcb-4a57-8149-d13b40e3ca27",
   "metadata": {},
   "source": [
    "When do you use a thread instead of a process?\n",
    "\n",
    "When uses processes, each *worker* is run in an individual process. By running each worker in an individual process, it avoids the GIL (global interpreter lock). The GIL is used to prevent multiple workers from updating a variable at the same time, potentially causing bugs.\n",
    "\n",
    "When using threads, each *worker* is a thread within the main process and is potentially slowed down by the GIL, e.g. if multiple threads wanted to use the same variable, they would each have to take it in turns. \n",
    "\n",
    "So, why not always use processes? There's an overhead in spawning multiple processes. So which to use depends on what you're trying to do.\n",
    "\n",
    "The general rule of thumb is:\n",
    "- If your operations are *I/O bound*, e.g. they're mainly waiting for other things to run, such as external API calls, then use **threads**.\n",
    "- If your operations are *compute bound* (aka *CPU bound*), e.g. they're mainly performing computations, then use **processes**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b0f72e-01c9-46f5-b671-a919b7875b50",
   "metadata": {},
   "source": [
    "## Joblib\n",
    "\n",
    "`joblib` is another library used for parallelism. Personally, I think the API looks a bit weird, but `joblib` seems to be common so it's a good idea to have a clue how it works.\n",
    "\n",
    "One important thing to note with `joblib` is that you explicitly need to tell it the number of workers to use with the `n_jobs` argument. Unless you know better, using `n_jobs=-1` (which uses all CPUs) is probably what you should be using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c39c8fa-6b82-4c9e-b786-87d1636933da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HELLO', 'WORLD', 'HOW', 'ARE', 'YOU', 'A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
      "5.411525584\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "t0 = time.monotonic()\n",
    "results = joblib.Parallel(n_jobs=-1)(joblib.delayed(fn)(t) for t in tokens)\n",
    "dt = time.monotonic() - t0\n",
    "print(results)\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8cba79-e3d1-4f27-a02e-629add55302a",
   "metadata": {},
   "source": [
    "## ThreadPool\n",
    "\n",
    "The final methods of parallelism we'll look at are `ThreadPool` (threads) and `Pool` (processes) from the `multiprocessing.pool` standard library. However, the official Python documentation recommends using `ThreadPoolExecutor` and `ProcessPoolExecutor` instead. We'll go over them just in case we see them in the wild, though the APIs are similar in some respects.\n",
    "\n",
    "We have a `map` function similar to the `ThreadPoolExecutor`. This one, however, always returns a list and not a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a85df722-2994-4f3a-a226-5a287e4fd4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HELLO', 'WORLD', 'HOW', 'ARE', 'YOU', 'A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
      "5.0165569580000025\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "t0 = time.monotonic()\n",
    "with ThreadPool() as pool:\n",
    "    results = pool.map(fn, tokens)\n",
    "dt = time.monotonic() - t0\n",
    "print(results)\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af3ecac-4319-44aa-8b39-9a00fe81f55b",
   "metadata": {},
   "source": [
    "If we'd like to return a generator, then we can use `imap` instead of `map`.\n",
    "\n",
    "**Note:** I've found that calling the `list` function on the generator outside of the context manager occasionally causes Jupyter Notebooks to hang. I am not sure what the cause of the issue is, but recommend calling it inside the context manager unless necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02a82eb5-a90b-4da5-94ff-66da765b908b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HELLO', 'WORLD', 'HOW', 'ARE', 'YOU', 'A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
      "5.0115710000000036\n"
     ]
    }
   ],
   "source": [
    "t0 = time.monotonic()\n",
    "with ThreadPool() as pool:\n",
    "    results = list(pool.imap(fn, tokens))\n",
    "dt = time.monotonic() - t0\n",
    "print(results)\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c106ef6a-e17b-4a7b-b196-31eca5560837",
   "metadata": {},
   "source": [
    "Similar to the `as_completed` method, the `pool` objects have an `imap_unordered` which returns an unordered generator.\n",
    "\n",
    "This also seems to have similar issues to above when calling `list` outside the context mananger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eda361c-63af-4619-8fb5-e8e91aa80a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'C', 'B', 'E', 'F', 'D', 'HOW', 'ARE', 'YOU', 'G', 'HELLO', 'WORLD']\n",
      "5.008692875000001\n"
     ]
    }
   ],
   "source": [
    "t0 = time.monotonic()\n",
    "with ThreadPool() as pool:\n",
    "    results = list(pool.imap_unordered(fn, tokens))\n",
    "dt = time.monotonic() - t0\n",
    "print(results)\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e55eb0-1fd0-4361-9539-7abf870096a2",
   "metadata": {},
   "source": [
    "As you may have guessed `ThreadPool` creates threads. Processes are created by `Pool`, which has the same API as `ThreadPool`. \n",
    "\n",
    "These processes have the same issue as the `ProcessPoolExecutor`, where they throw errors in Jupyter Notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b11e0e35-276c-4788-8fb1-5d37de152c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from multiprocessing.pool import Pool\n",
    "\n",
    "#t0 = time.monotonic()\n",
    "#with Pool() as pool:\n",
    "#    results = list(pool.imap_unordered(fn, tokens)))\n",
    "#dt = time.monotonic() - t0\n",
    "#print(results)\n",
    "#print(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d869a6f9-91af-4d8c-917c-d6b9a564b768",
   "metadata": {},
   "source": [
    "This should be enough information for basic parallel computation in Python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
