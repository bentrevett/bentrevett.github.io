{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c2dd28e-ade8-435f-a670-f354958a9b15",
   "metadata": {},
   "source": [
    "# Building Decision Trees and Random Forests from scratch\n",
    "\n",
    "Decision trees are a fundamental algorithm in machine learning. Random forests are a method of improving the performance of decision trees by training an _ensemble_ of them, i.e. training multiple decision trees and aggregating their results.\n",
    "\n",
    "Our decision trees and random forests will be trained on the BMI dataset from [here](https://www.kaggle.com/datasets/yersever/500-person-gender-height-weight-bodymassindex) which I've downloaded and renamed to `bmi-data.csv`. We'll open it in pandas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff7525de-162f-40ce-bb31-c95af1383ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>174</td>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>189</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>185</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>195</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>149</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Female</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Female</td>\n",
       "      <td>184</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Female</td>\n",
       "      <td>141</td>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Male</td>\n",
       "      <td>150</td>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Male</td>\n",
       "      <td>173</td>\n",
       "      <td>131</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Height  Weight  Index\n",
       "0      Male     174      96      4\n",
       "1      Male     189      87      2\n",
       "2    Female     185     110      4\n",
       "3    Female     195     104      3\n",
       "4      Male     149      61      3\n",
       "..      ...     ...     ...    ...\n",
       "495  Female     150     153      5\n",
       "496  Female     184     121      4\n",
       "497  Female     141     136      5\n",
       "498    Male     150      95      5\n",
       "499    Male     173     131      5\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"bmi-data.csv\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82ce2a9",
   "metadata": {},
   "source": [
    "Our dataset has genders, heights, weights and BMIs for 500 people. We'll use the gender, height and weight to predict the BMI. To make things slightly easier, instead of predicting BMI directly, we'll predict if the BMI is obese or not, which is when the Index column is >= 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a90b7f7f-f295-49c3-8724-3ee81f49baaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Obese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>174</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>189</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>185</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>195</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>149</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Female</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Female</td>\n",
       "      <td>184</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Female</td>\n",
       "      <td>141</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Male</td>\n",
       "      <td>150</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Male</td>\n",
       "      <td>173</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Height  Weight  Obese\n",
       "0      Male     174      96      1\n",
       "1      Male     189      87      0\n",
       "2    Female     185     110      1\n",
       "3    Female     195     104      0\n",
       "4      Male     149      61      0\n",
       "..      ...     ...     ...    ...\n",
       "495  Female     150     153      1\n",
       "496  Female     184     121      1\n",
       "497  Female     141     136      1\n",
       "498    Male     150      95      1\n",
       "499    Male     173     131      1\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Obese\"] = (data[\"Index\"] >= 4).astype(\"int\")\n",
    "data = data.drop(\"Index\", axis=1)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b329465-7e6b-4067-91e3-0f30e82dc3d2",
   "metadata": {},
   "source": [
    "How do we predict if someone is obese using a decision tree? A decision tree consists of a series of binary rules (they either have a yes/no outcome), e.g. if weight >= 100 kg, then the tree predicts the person is obese. The key concept is that the tree is made of multiple stacked rules, and each rule is used to _split_ the data. At each split, some data is routed in one direction and some another. The data is continuously split until it reaches the point where it cannot be split anymore, which is where our decision tree makes a prediction. Each split in the tree is called a _node_, and the final nodes (where no more splits are made) are called _leaf nodes_.\n",
    "\n",
    "The decision tree starts with no nodes, these are learned when the decision tree is trained (or fit) on the training data. Once the tree is trained, we can use it to make predictions on new data. The algorithm for training a decision tree uses a _cost function_ to determine how to perform a split at each node. The cost function uses _impurity_, which measures how likely the target value is to be incorrectly classified. The two most common cost functions are the Gini index and entropy, here we'll just focus on entropy.\n",
    "\n",
    "Let's compare at what happens if we make a single split in the data when we predict obesity at weight >= 100 kg and obesity at weight >= 80 kg. We can count the number of mistakes made both splits:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b5373b-e34c-4d54-bf92-1a71e1078f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 63)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100kg = data[(data[\"Weight\"] >= 100) & (data[\"Obese\"] == 0)]\n",
    "df_80kg = data[(data[\"Weight\"] >= 80) & (data[\"Obese\"] == 0)]\n",
    "\n",
    "len(df_100kg), len(df_80kg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db50957c",
   "metadata": {},
   "source": [
    "We can see that splitting at 100 kg made 18 mistakes, and splitting at 80 kg made 63 mistakes. Therefore the split at 100 kg is less impure and thus is a better split. Cost functions are used to find splits that minimize impurity.\n",
    "\n",
    "Entropy can be used as a measurement of impurity and is given by: $$H(X) = -\\sum_{i=1}^{n} p(x_i) \\log_2 p(x_i)$$ where $p(x_i)$ is the probability of class $x_i$ occurring. The entropy is 0 when all the data is of the same class (minimum impurity), and is 1 when the data is evenly split between classes (maximum impurity).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb41f186-e638-4fc1-b6f5-9a3cf3b79a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def entropy(x):\n",
    "    assert isinstance(x, pd.Series)\n",
    "    p = x.value_counts() / len(x)\n",
    "    # 1e-10 is used to stop np.log2 throwing a division by zero error\n",
    "    entropy = -np.sum(p * np.log2(p + 1e-10))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabc260b",
   "metadata": {},
   "source": [
    "We can now calculate the impurity for both of the splits, where we should see that the split at 100 kg has a lower impurity than the split at 80 kg (i.e. it makes less mistakes, is less impure, and is a better split).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bbe8415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22364166419594184"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy((data[\"Weight\"] >= 100) & (data[\"Obese\"] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0f1b220-9bf2-4d5d-b135-4012602aaed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5463652176690357"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy((data[\"Weight\"] >= 80) & (data[\"Obese\"] == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a56a7-52d9-4a98-9071-b32a1a4260cb",
   "metadata": {},
   "source": [
    "We know how to calculate impurity to tell us if a split is good or not, but what we'd like to do is calculate how much improvement in purity a split gives us compared to the data before the split. For this we use _information gain_. Information gain quantifies how much impurity in the data is reduced after a split. It is calculated as the difference in impurity before and after the split and uses entropy to measure this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d8e86f0-dbbd-412b-8b4d-d74be1827ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_information_gain(series, mask):\n",
    "    n_true_split = sum(mask)\n",
    "    n_false_split = len(mask) - n_true_split\n",
    "    if n_true_split == 0 or n_false_split == 0:\n",
    "        return 0\n",
    "    original_impurity = entropy(series)\n",
    "    true_split_impurity = entropy(series[mask])\n",
    "    false_split_impurity = entropy(series[~mask])\n",
    "    weighted_average_impurity = (\n",
    "        n_true_split / len(mask) * true_split_impurity\n",
    "        + n_false_split / len(mask) * false_split_impurity\n",
    "    )\n",
    "    information_gain = original_impurity - weighted_average_impurity\n",
    "    return information_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8216e84-14f4-4204-9360-a69f74a650f5",
   "metadata": {},
   "source": [
    "We calculate the impurity of the data before the split, `original_impurity`, the impurities of the subsets of data created after the split, `true_split_impurity` and `false_split_impurity`, and then the combined impurity after the split taking into account the proportion of data in each subset to get the entropy after the split as `weighted_average_impurity`. The information gain is then the difference between the original entropy and the weighted average entropy after the split.\n",
    "\n",
    "We can see that just as splitting at >= 100 kg gave us a lower impurity, it also gave us a higher information gain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea97512a-6b36-4db0-984e-ac149eff68e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35468741526665915"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_information_gain(data[\"Obese\"], data[\"Weight\"] >= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06eafaf1-7150-440a-bcc3-9ca0307b46f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3062635617880082"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_information_gain(data[\"Obese\"], data[\"Weight\"] >= 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940bccfb",
   "metadata": {},
   "source": [
    "Now we know how to measure how good a split is, we can use this to build a decision tree. The steps we need to take on each node are:\n",
    "\n",
    "1. Calculate the information gain for all variables\n",
    "2. Choose the split that generates the highest information gain\n",
    "3. Repeat until we hit some stopping criteria\n",
    "\n",
    "When splitting numeric variables, e.g. weight, we get all values that variables takes within the current split, and for each value calculate the information gain when filtering all values _less_ than that value, then see which gives the highest information gain.\n",
    "\n",
    "When splitting categorical variables, e.g. gender, we get all combinations of values that variables takes within the current split and calculate the information gain for each combination. Note: if you have a significant number of categorical variables within a column the number of combinations explodes, so libraries that implement decision trees/random forests usually have a better way of handling this.\n",
    "\n",
    "We'll implement a function to get all potential combinations for a categorical variable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a5b5d9c-fd48-4324-a51c-d4adc8f8ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def get_categorical_options(series):\n",
    "    assert isinstance(series, pd.Series)\n",
    "    series = set(series)\n",
    "    options = []\n",
    "    for i, _ in enumerate(series):\n",
    "        subset = itertools.combinations(series, i + 1)\n",
    "        options.extend(subset)\n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc5362bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Green',),\n",
       " ('Red',),\n",
       " ('Blue',),\n",
       " ('Green', 'Red'),\n",
       " ('Green', 'Blue'),\n",
       " ('Red', 'Blue'),\n",
       " ('Green', 'Red', 'Blue')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_categorical_options(pd.Series([\"Red\", \"Red\", \"Blue\", \"Blue\", \"Green\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d781a1b",
   "metadata": {},
   "source": [
    "Putting all this together, we can now define a function which, when given a feature column of a DataFrame and the label column, will calculate the information gain for all possible splits of that feature and return the best split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c9e4114-27a0-4166-a0fe-3f3e2a07ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_information_gain(x_series, y_series):\n",
    "    is_numeric = x_series.dtype != \"object\"\n",
    "    if is_numeric:\n",
    "        # Skip the first value as it is the minimum and if we split on it one of the splits will be empty.\n",
    "        split_values = x_series.sort_values().unique()[1:].tolist()\n",
    "    else:\n",
    "        split_values = get_categorical_options(x_series)\n",
    "    results = []\n",
    "    if not split_values:\n",
    "        # Handle the case when all values are the same, e.g. all one value.\n",
    "        return {\"split_value\": None, \"information_gain\": 0, \"is_numeric\": is_numeric}\n",
    "    for split_value in split_values:\n",
    "        mask = x_series < split_value if is_numeric else x_series.isin(split_value)\n",
    "        split_information_gain = get_information_gain(y_series, mask)\n",
    "        results.append(\n",
    "            {\n",
    "                \"value\": split_value,\n",
    "                \"information_gain\": split_information_gain,\n",
    "            }\n",
    "        )\n",
    "    results = sorted(results, key=lambda x: x[\"information_gain\"], reverse=True)\n",
    "    best_split_value = results[0][\"value\"]\n",
    "    best_information_gain = results[0][\"information_gain\"]\n",
    "    return {\n",
    "        \"split_value\": best_split_value,\n",
    "        \"information_gain\": best_information_gain,\n",
    "        \"is_numeric\": is_numeric,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90ea4f1",
   "metadata": {},
   "source": [
    "We can use this to get the best split for a given feature:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b60045fd-90e2-4978-968f-5352ed62ec73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'split_value': 174,\n",
       " 'information_gain': 0.06474831770089884,\n",
       " 'is_numeric': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_max_information_gain(data[\"Height\"], data[\"Obese\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74faf47",
   "metadata": {},
   "source": [
    "To verify, we can plot the information gain for each split value:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d36f64a-0ac8-4556-a9a1-93b0150dca28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Information Gain')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "values = data[\"Height\"].sort_values().unique()[1:]\n",
    "information_gains = [\n",
    "    get_information_gain(data[\"Height\"], data[\"Height\"] < value) for value in values\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(values, information_gains)\n",
    "ax.set_xlabel(\"Height\")\n",
    "ax.set_ylabel(\"Information Gain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94509857",
   "metadata": {},
   "source": [
    "Now we can calculate the highest information gain for each feature, we'll write a function to iterate across all feature columns, calculate the best split for each, and then return the best split overall:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bab774ed-4221-47c6-b40d-9d36727dc275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_split(df, y):\n",
    "    column_max_information_gains = [\n",
    "        {\"column_name\": column, **get_max_information_gain(df[column], df[y])}\n",
    "        for column in df.columns\n",
    "        if column != y  # We don't want to split on the target variable\n",
    "    ]\n",
    "    best_split_info = sorted(\n",
    "        column_max_information_gains, key=lambda x: x[\"information_gain\"]\n",
    "    )[-1]\n",
    "    return best_split_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64351cb",
   "metadata": {},
   "source": [
    "We can use this to find out that the best split for the initial data is splitting at weight >= 103 kg.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95c37e9f-4bcf-4952-adf2-7596ca996337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'column_name': 'Weight',\n",
       " 'split_value': 103,\n",
       " 'information_gain': 0.3824541370911896,\n",
       " 'is_numeric': True}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_info = get_best_split(data, \"Obese\")\n",
    "\n",
    "split_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea75242b",
   "metadata": {},
   "source": [
    "The last of the helper functions is to use the information about the best split to actually split the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd999326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_split(df, split_info):\n",
    "    column_name = split_info[\"column_name\"]\n",
    "    split_value = split_info[\"split_value\"]\n",
    "    is_numeric = split_info[\"is_numeric\"]\n",
    "    assert is_numeric == (df[column_name].dtype != \"object\")\n",
    "    if is_numeric:\n",
    "        mask = df[column_name] < split_value\n",
    "    else:\n",
    "        mask = df[column_name].isin(split_value)\n",
    "    df_left = df[mask]\n",
    "    df_right = df[~mask]\n",
    "    return df_left, df_right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7976b84a",
   "metadata": {},
   "source": [
    "Splitting at weight >= 103 kg gives us two subsets of data. We can see that there are 229 and 271 examples in each split. With 229 in the _left_ split, where weight < 103 kg, and 271 in the _right_ split, where weight >= 103 kg.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab56bf34-954c-4945-ba4b-011e02f3df3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 229, 271)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left, right = make_split(data, split_info)\n",
    "\n",
    "len(data), len(left), len(right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7951c7b",
   "metadata": {},
   "source": [
    "We can split each each of these subsets, and then split the resulting subsets, and so on, until we reach some stopping criteria, which is how we build our decision tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7c5a98d-1e93-4c65-814b-310918998588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'column_name': 'Height',\n",
       " 'split_value': 178,\n",
       " 'information_gain': 0.28026630900174687,\n",
       " 'is_numeric': True}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_info = get_best_split(left, \"Obese\")\n",
    "\n",
    "split_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93f9aa35-eac3-4a21-8cc7-361b01dcd678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'column_name': 'Weight',\n",
       " 'split_value': 116,\n",
       " 'information_gain': 0.09289094500737183,\n",
       " 'is_numeric': True}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_info = get_best_split(right, \"Obese\")\n",
    "\n",
    "split_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c32d6e",
   "metadata": {},
   "source": [
    "We define a `DecisionNode` class which will represent the nodes in our decision tree. Each node contains information about the split (the column, value, if it was numeric), the left and right children nodes, if the tree is classification or regression, and the predicted label (only when the node is a leaf node).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b1c4f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    def __init__(\n",
    "        self,\n",
    "        column,\n",
    "        split_value,\n",
    "        is_numeric,\n",
    "        left,\n",
    "        right,\n",
    "        is_classification,\n",
    "        prediction,\n",
    "    ):\n",
    "        self.column = column\n",
    "        self.split_value = split_value\n",
    "        self.is_numeric = is_numeric\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.is_classification = is_classification\n",
    "        self.prediction = prediction\n",
    "\n",
    "    def __repr__(self, depth=0, indent=\"    \"):\n",
    "        # Print the tree structure\n",
    "        prefix = depth * indent\n",
    "        if self.is_leaf():\n",
    "            return f\"{prefix}Leaf(prediction={self.prediction})\"\n",
    "        description = f\"{prefix}DecisionNode(column={self.column}, split_value={self.split_value}, is_numeric={self.is_numeric})\\n\"\n",
    "        if self.left:\n",
    "            description += f\"{prefix}left:\\n{self.left.__repr__(depth + 1, indent)}\\n\"\n",
    "        if self.right:\n",
    "            description += f\"{prefix}right:\\n{self.right.__repr__(depth + 1, indent)}\"\n",
    "        return description\n",
    "\n",
    "    def is_leaf(self):\n",
    "        # If a node has no left and right children, it is a leaf node\n",
    "        return self.left is None and self.right is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877f15b5",
   "metadata": {},
   "source": [
    "Finally, we want to build our tree, which we do by recursively splitting the data until we reach some stopping criteria. When we reach a stopping criteria, we create a leaf node that makes a prediction. If it's a classification problem, we predict the most common class in the subset of data, and if it's a regression problem, we predict the mean of the subset of data. Our `build_tree` function is wrapped in a `train_decision_tree` function which builds the tree from a depth of zero and returns the tree itself.\n",
    "\n",
    "The stopping criteria we'll use are:\n",
    "\n",
    "-   Maximum depth: the maximum number of splits we want to make\n",
    "-   Minimum samples: the minimum number of samples we want to have in a node before we stop splitting\n",
    "-   Minimum information gain: the minimum information gain we want to have before we stop splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2efe3f4d-891c-463b-899c-80597cc15f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(\n",
    "    df, y, depth, max_depth, min_samples_split, min_information_gain, is_classification\n",
    "):\n",
    "    # Check if we have reached the maximum depth\n",
    "    if depth >= max_depth:\n",
    "        return create_leaf_node(df, y, is_classification)\n",
    "\n",
    "    # Check if we have reached the minimum number of samples required to split\n",
    "    if len(df) < min_samples_split:\n",
    "        return create_leaf_node(df, y, is_classification)\n",
    "\n",
    "    # Get the best split\n",
    "    split_info = get_best_split(df, y)\n",
    "\n",
    "    # Check if the best split has enough information gain\n",
    "    if split_info[\"information_gain\"] < min_information_gain:\n",
    "        return create_leaf_node(df, y, is_classification)\n",
    "\n",
    "    # Make the split\n",
    "    df_left, df_right = make_split(df, split_info)\n",
    "\n",
    "    # Build the left and right subtrees\n",
    "    subtree_left = build_tree(\n",
    "        df_left,\n",
    "        y,\n",
    "        depth + 1,\n",
    "        max_depth,\n",
    "        min_samples_split,\n",
    "        min_information_gain,\n",
    "        is_classification,\n",
    "    )\n",
    "\n",
    "    subtree_right = build_tree(\n",
    "        df_right,\n",
    "        y,\n",
    "        depth + 1,\n",
    "        max_depth,\n",
    "        min_samples_split,\n",
    "        min_information_gain,\n",
    "        is_classification,\n",
    "    )\n",
    "\n",
    "    # Make the decision node\n",
    "    return DecisionNode(\n",
    "        column=split_info[\"column_name\"],\n",
    "        split_value=split_info[\"split_value\"],\n",
    "        is_numeric=split_info[\"is_numeric\"],\n",
    "        left=subtree_left,\n",
    "        right=subtree_right,\n",
    "        is_classification=is_classification,\n",
    "        prediction=None,\n",
    "    )\n",
    "\n",
    "\n",
    "def create_leaf_node(df, y, is_classification):\n",
    "    # If it is a classification problem, we return the mode of the target variable\n",
    "    if is_classification:\n",
    "        prediction = df[y].mode()[0]\n",
    "    # If it is a regression problem, we return the mean of the target variable\n",
    "    else:\n",
    "        prediction = df[y].mean()\n",
    "\n",
    "    return DecisionNode(\n",
    "        column=None,\n",
    "        split_value=None,\n",
    "        is_numeric=None,\n",
    "        left=None,\n",
    "        right=None,\n",
    "        is_classification=is_classification,\n",
    "        prediction=prediction,\n",
    "    )\n",
    "\n",
    "\n",
    "def train_decision_tree(\n",
    "    df,\n",
    "    y,\n",
    "    max_depth,\n",
    "    min_samples_split,\n",
    "    min_information_gain,\n",
    "    is_classification,\n",
    "):\n",
    "    return build_tree(\n",
    "        df, y, 0, max_depth, min_samples_split, min_information_gain, is_classification\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544916ee",
   "metadata": {},
   "source": [
    "Now, we can specify which column is our label column, the values of our stopping criteria, and if our tree is doing classification or regression, then train our tree.\n",
    "\n",
    "Note: Ideally we should use be using a train/validation/test splits of our data, but for simplicity here we'll just train on the entire dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d65d461-a722-4be1-b949-57490c926f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"Obese\"\n",
    "max_depth = 10\n",
    "min_samples_split = 2\n",
    "min_information_gain = 0.1\n",
    "is_classification = True\n",
    "\n",
    "tree = train_decision_tree(\n",
    "    data,\n",
    "    y,\n",
    "    max_depth,\n",
    "    min_samples_split,\n",
    "    min_information_gain,\n",
    "    is_classification,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaae4e6",
   "metadata": {},
   "source": [
    "We can also see the individual splits in our tree. We can see that the first split was at weight >= 103 kg, the left split from that (where weight < 103 kg) was split at height >= 178, and the right split (where weight >= 103 kg) was already a leaf node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47d36982-6371-4355-92e3-e4b70a5a97d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionNode(column=Weight, split_value=103, is_numeric=True)\n",
       "left:\n",
       "    DecisionNode(column=Height, split_value=178, is_numeric=True)\n",
       "    left:\n",
       "        DecisionNode(column=Weight, split_value=66, is_numeric=True)\n",
       "        left:\n",
       "            Leaf(prediction=0)\n",
       "        right:\n",
       "            DecisionNode(column=Height, split_value=151, is_numeric=True)\n",
       "            left:\n",
       "                DecisionNode(column=Weight, split_value=67, is_numeric=True)\n",
       "                left:\n",
       "                    DecisionNode(column=Height, split_value=149, is_numeric=True)\n",
       "                    left:\n",
       "                        Leaf(prediction=1)\n",
       "                    right:\n",
       "                        Leaf(prediction=0)\n",
       "                right:\n",
       "                    Leaf(prediction=1)\n",
       "            right:\n",
       "                DecisionNode(column=Weight, split_value=82, is_numeric=True)\n",
       "                left:\n",
       "                    DecisionNode(column=Height, split_value=161, is_numeric=True)\n",
       "                    left:\n",
       "                        DecisionNode(column=Weight, split_value=74, is_numeric=True)\n",
       "                        left:\n",
       "                            Leaf(prediction=0)\n",
       "                        right:\n",
       "                            DecisionNode(column=Height, split_value=154, is_numeric=True)\n",
       "                            left:\n",
       "                                DecisionNode(column=Weight, split_value=78, is_numeric=True)\n",
       "                                left:\n",
       "                                    Leaf(prediction=1)\n",
       "                                right:\n",
       "                                    Leaf(prediction=0)\n",
       "                            right:\n",
       "                                Leaf(prediction=1)\n",
       "                    right:\n",
       "                        Leaf(prediction=0)\n",
       "                right:\n",
       "                    DecisionNode(column=Height, split_value=173, is_numeric=True)\n",
       "                    left:\n",
       "                        Leaf(prediction=1)\n",
       "                    right:\n",
       "                        DecisionNode(column=Weight, split_value=95, is_numeric=True)\n",
       "                        left:\n",
       "                            Leaf(prediction=0)\n",
       "                        right:\n",
       "                            Leaf(prediction=1)\n",
       "    right:\n",
       "        Leaf(prediction=0)\n",
       "right:\n",
       "    Leaf(prediction=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfecefca",
   "metadata": {},
   "source": [
    "We can make predictions with our tree by recursively traversing the tree with our input data until we hit a leaf node, and then returning the prediction at that leaf node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdf0165f-8568-4241-bb2e-2a7f76f85114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict_tree(tree, example):\n",
    "    if tree.is_leaf():\n",
    "        return tree.prediction\n",
    "    if tree.is_numeric:\n",
    "        if example[tree.column] < tree.split_value:\n",
    "            return _predict_tree(tree.left, example)\n",
    "        else:\n",
    "            return _predict_tree(tree.right, example)\n",
    "    else:\n",
    "        if example[tree.column] in tree.split_value:\n",
    "            return _predict_tree(tree.left, example)\n",
    "        else:\n",
    "            return _predict_tree(tree.right, example)\n",
    "\n",
    "\n",
    "def predict_tree(tree, x):\n",
    "    if isinstance(x, pd.Series):\n",
    "        return _predict_tree(tree, x)\n",
    "    else:\n",
    "        assert isinstance(x, pd.DataFrame)\n",
    "        return x.apply(lambda row: _predict_tree(tree, row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd30f784",
   "metadata": {},
   "source": [
    "We can make a prediction for a single example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9216abe0-da28-4218-9edf-1d47aef2455f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender    Male\n",
       "Height     174\n",
       "Weight      96\n",
       "Obese        1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = data.iloc[0]\n",
    "\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa2f778c-1610-4d84-84ec-9917feb9b128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_tree(tree, example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6815b364",
   "metadata": {},
   "source": [
    "We can also make predictions for all of the examples in the DataFrame:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8550a121-307f-4226-9e4a-b045c34394ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_tree(tree, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b453fabd-5f84-44b9-ac13-7b6f6394c032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "495    1\n",
       "496    1\n",
       "497    1\n",
       "498    1\n",
       "499    1\n",
       "Length: 500, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98697df0",
   "metadata": {},
   "source": [
    "We can see that our predictions are not 100% accurate, even though we trained our tree on the entire dataset. This is because our tree is overfitting the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2926d7e-ae58-42a0-bb14-e6da06f7840f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictions == data[\"Obese\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8b540c3-7f17-42ff-b01a-30f8918d59d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = data[data[\"Obese\"] != predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "379aa34a-566a-4b34-a3fa-108488b7b5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Obese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>195</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Male</td>\n",
       "      <td>189</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Female</td>\n",
       "      <td>197</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Female</td>\n",
       "      <td>190</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Female</td>\n",
       "      <td>194</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Male</td>\n",
       "      <td>194</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Male</td>\n",
       "      <td>194</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Female</td>\n",
       "      <td>168</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Female</td>\n",
       "      <td>192</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Male</td>\n",
       "      <td>183</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Female</td>\n",
       "      <td>169</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Female</td>\n",
       "      <td>195</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>Male</td>\n",
       "      <td>198</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Height  Weight  Obese\n",
       "3    Female     195     104      0\n",
       "5      Male     189     104      0\n",
       "36   Female     197     114      0\n",
       "82   Female     190     105      0\n",
       "92   Female     194     111      0\n",
       "137    Male     194     108      0\n",
       "146    Male     194     106      0\n",
       "149  Female     168     115      0\n",
       "184  Female     192     108      0\n",
       "291    Male     183     105      0\n",
       "296  Female     169      88      0\n",
       "400  Female     195     104      0\n",
       "469    Male     198     109      0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb245e2",
   "metadata": {},
   "source": [
    "Next, we'll build a random forest. A random forest is an ensemble of decision trees. We train multiple decision trees each using a _bootstrapped_ version of the original dataset. In other words, each tree is trained on a dataset which is the same size (number of examples) as the original data but the examples are sampled from the original dataset with replacement. This technique is called _bagging_ (or _bootstrap aggregating_).\n",
    "\n",
    "After we've trained the trees (a forest) we can use them to make predictions. For classification problems, we use the most common prediction from all the trees, and for regression problems, we use the mean prediction from all the trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "981dc982-88de-4f50-bbe9-5e06e9a60a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "\n",
    "def train_random_forest(\n",
    "    data,\n",
    "    y,\n",
    "    n_trees=10,\n",
    "    max_depth=2,\n",
    "    min_samples_split=2,\n",
    "    min_information_gain=0.01,\n",
    "    is_classification=True,\n",
    "):\n",
    "    trees = []\n",
    "    for _ in tqdm.tqdm(range(n_trees)):\n",
    "        # Bootstrap sample the data\n",
    "        sample = data.sample(frac=1, replace=True)\n",
    "        # Train a decision tree on the bootstrapped sample\n",
    "        tree = train_decision_tree(\n",
    "            sample,\n",
    "            y,\n",
    "            max_depth,\n",
    "            min_samples_split,\n",
    "            min_information_gain,\n",
    "            is_classification,\n",
    "        )\n",
    "        trees.append(tree)\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df55d464",
   "metadata": {},
   "source": [
    "We'll train our forest, which consists of 25 trees, using the same stopping criteria as before:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29b65fc1-5390-44de-91bd-bf7f675cbacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:33<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "y = \"Obese\"\n",
    "n_trees = 25\n",
    "max_depth = 10\n",
    "min_samples_split = 2\n",
    "min_information_gain = 0.1\n",
    "is_classification = True\n",
    "\n",
    "forest = train_random_forest(\n",
    "    data,\n",
    "    y,\n",
    "    n_trees,\n",
    "    max_depth,\n",
    "    min_samples_split,\n",
    "    min_information_gain,\n",
    "    is_classification,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36cd567",
   "metadata": {},
   "source": [
    "Finally, we'll define functions the make our predictions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8fe3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict_forest(forest, x):\n",
    "    predictions = [predict_tree(tree, x) for tree in forest]\n",
    "    is_classification = forest[0].is_classification\n",
    "    if is_classification:\n",
    "        return max(set(predictions), key=predictions.count)\n",
    "    else:\n",
    "        return np.mean(predictions)\n",
    "\n",
    "\n",
    "def predict_forest(forest, x):\n",
    "    if isinstance(x, pd.Series):\n",
    "        return _predict_forest(forest, x)\n",
    "    else:\n",
    "        assert isinstance(x, pd.DataFrame)\n",
    "        return x.apply(lambda row: _predict_forest(forest, row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ada6d3",
   "metadata": {},
   "source": [
    "We can predict on one sample:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55ff72d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_forest(forest, example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c8ac1f",
   "metadata": {},
   "source": [
    "And we can also predict on the entire DataFrame, and see that our predictions are more accurate than using a single decision tree (2 errors vs 13):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55cd1c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predict_forest(forest, data) == data[\"Obese\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e69b9c-bafe-4429-bf6b-662a1a8d2430",
   "metadata": {},
   "source": [
    "As we can see, random forests are a small extension (both conceptually and in code) to decision trees, but significantly improve their performance. For using random forests in actual code, I'd recommend [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) or [xgboost](https://xgboost.readthedocs.io/en/stable/index.html)/[catboost](https://catboost.ai/en/docs/) (both of which are not actually random forests but work in a similar way -- by using an ensemble of decision trees)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
