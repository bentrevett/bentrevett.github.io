{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2321b61-6fb7-4b86-a257-6d29f8e83ecf",
   "metadata": {},
   "source": [
    "# Making LLMs smarter with structured generation and Outlines\n",
    "\n",
    "Structured generation is a method of improving performance of your LLM without doing additional training or increasing inference time. It constrains the output of your LLM to a specified schema, allowing it to be more predictable and machine readable. It *can* also improve performance (though this is [contested](https://blog.dottxt.co/say-what-you-mean.html)); though today we'll show how using the [Outlines](https://github.com/dottxt-ai/outlines) library for structured does generate some improvements on a small anecdotal example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8bb71d2-6ca4-4467-8d41-b0164816604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import outlines\n",
    "import torch\n",
    "import string\n",
    "import pydantic\n",
    "import enum\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dac925-faa9-4dcf-8db0-f4a5ecd6cdab",
   "metadata": {},
   "source": [
    "We'll use the [Qwen2.5-0.5B-Instruct](https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct) model to perform our experiments. The model is relatively capable for its size and is good for using to test different libraries.\n",
    "\n",
    "First, we'll load it using the HuggingFace [transformers](https://huggingface.co/docs/transformers/en/index) library and use it to initialise a [text generation pipeline](https://huggingface.co/docs/transformers/en/main_classes/pipelines#transformers.TextGenerationPipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c81de54-dd0c-4bcb-90b3-0d308606c896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "pipe = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a807e6-6f42-4cf1-9f83-3580f72cfbe6",
   "metadata": {},
   "source": [
    "Next, we'll use the pipeline to generate a response for our prompt we'll be using to test the different structured generation methods: getting the answer to 40 + 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "449f1652-adde-40de-93f7-fad699537100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is 40 + 2 ? Give me the answer only. \"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": prompt,\n",
    "    },\n",
    "]\n",
    "\n",
    "results = pipe(\n",
    "    messages, \n",
    "    do_sample=False,\n",
    "    max_new_tokens=25,\n",
    ")\n",
    "\n",
    "output = results[0][\"generated_text\"][-1][\"content\"]\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e490ea5-83c3-4ca2-ba5c-9e58072804c3",
   "metadata": {},
   "source": [
    "Last I checked, 40 + 2 = 42. I guess deep learning is hitting a wall after all. Now let's see if structured generation can save us. \n",
    "\n",
    "Outlines has a wrapper around models provided by the transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b72de2d-740d-4e94-ada3-92b7d28a7fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = outlines.models.transformers(\n",
    "    model_name,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7545317f-b795-427d-a36b-edf7c93d7948",
   "metadata": {},
   "source": [
    "Generating output using Outlines requires two steps: \n",
    "- creating a generator which specifies how the text will be generated\n",
    "- using that generator with the prompt and some parameters to get an output\n",
    "\n",
    "The simplest generator is `generate.text`, which simply generates unstructured text. We use `samplers.greedy` to effectively do greedy sampling with a temperature of zero to get deterministic outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1acd7b11-3bce-40c6-8d79-080fd0838c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "\n",
      "The answer is 22. \n",
      "\n",
      "To arrive at this answer, simply add the two numbers together:\n",
      "\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "generator = outlines.generate.text(\n",
    "    model,\n",
    "    sampler=outlines.samplers.greedy(),\n",
    ")\n",
    "\n",
    "output = generator(\n",
    "    prompt, \n",
    "    max_tokens=25,\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff77581a-57b2-4658-ba5f-36359d295222",
   "metadata": {},
   "source": [
    "You'll see that the output is still wrong. But why didn't this generate the same output as using the transformers' text generation pipeline? This is because the text generation pipeline used the *messages* format, whereas the `generate.text` generates autoregressively using the prompt directly.\n",
    "\n",
    "Our first taste of using structured generation is with `generate.choice`. Here, we pass a list of strings to the generator and it can only generate one of those. Here, we allow it to generate any number between 0-99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12f60157-69ee-468c-a839-d1f4162748e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.\n"
     ]
    }
   ],
   "source": [
    "generator = outlines.generate.choice(\n",
    "    model, \n",
    "    choices=[f\"{i}.\" for i in range(100)],\n",
    "    sampler=outlines.samplers.greedy(),\n",
    ")\n",
    "\n",
    "output = generator(\n",
    "    prompt, \n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3eaecc-7550-4315-af62-ce35052982fe",
   "metadata": {},
   "source": [
    "Unfortunately, it still gets the answer wrong. What if it needs a little more help? We'll do the same thing again but put the equation into the choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc0e4ca8-67a3-48fc-89bc-88b7663175b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 + 2 = 42.\n"
     ]
    }
   ],
   "source": [
    "generator = outlines.generate.choice(\n",
    "    model, \n",
    "    [f\"40 + 2 = {i}.\" for i in range(100)],\n",
    "    sampler=outlines.samplers.greedy(),\n",
    ")\n",
    "\n",
    "output = generator(\n",
    "    prompt, \n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fdd806-5fc4-4b1f-bcc9-84b712e181cb",
   "metadata": {},
   "source": [
    "And there we go, that's one way to make a model with 500 million parameters do simple addition.\n",
    "\n",
    "Let's try a few other `generate` methods. The first is `generate.format` which forces the output to be a valid Python type, here an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46ae0ba0-90e2-42ee-92fa-e05359535ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "generator = outlines.generate.format(\n",
    "    model, \n",
    "    int,\n",
    "    sampler=outlines.samplers.greedy(),\n",
    ")\n",
    "\n",
    "output = generator(\n",
    "    prompt, \n",
    "    max_tokens=25,\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed00b732-527a-4916-a511-1599028d370c",
   "metadata": {},
   "source": [
    "It's definitely an integer, but not the one we wanted. Personally, I've never found `generate.format` to be that useful, or been able to get greate results out of it. (You may have noticed I had to add `max_tokens` back, this was because if I didn't, it would generate integers until it hits the full output context length.)\n",
    "\n",
    "Next up, is probably the second most useful method, `generate.regex`, which allows us to pass a regex pattern that all outputs will conform to. (`generate.choice` uses `generate.regex` under the hood.).\n",
    "\n",
    "Here, we can ensure it only generates outputs with one or more integers, followed by a period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6fa3245-3f0f-43cf-9ad6-6cda3a7d5ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.\n"
     ]
    }
   ],
   "source": [
    "generator = outlines.generate.regex(\n",
    "    model, \n",
    "    r\"\\d+\\.\",\n",
    "    sampler=outlines.samplers.greedy(),\n",
    ")\n",
    "\n",
    "output = generator(\n",
    "    prompt, \n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f66182-7527-470e-9dcd-2358652c007d",
   "metadata": {},
   "source": [
    "Unsurprisingly, this generated the same thing as our first test with `generate.choices`. What if we repeated our second experiment with `generate.choices`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2137f85-5371-4153-9695-f37c17e29d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 + 2 = 42.\n"
     ]
    }
   ],
   "source": [
    "generator = outlines.generate.regex(\n",
    "    model, \n",
    "    r\"40 \\+ 2 = \\d+\\.\",\n",
    "    sampler=outlines.samplers.greedy(),\n",
    ")\n",
    "\n",
    "output = generator(\n",
    "    prompt, \n",
    "    max_tokens=25,\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef8595d-0ceb-463f-81ce-13095d7e3497",
   "metadata": {},
   "source": [
    "> The definition of insanity is doing the same thing over and over again and expecting a different result.\n",
    "\n",
    "One trick we can do is state an answer is obvious, because online (the training data) nobody would ever say something was obvious unless they were giving the actual correct answer. Thus, the LLM is more likely to generate the actual answer after outputting that the answer is obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d456fd4f-aeeb-4f4b-82ac-6c8830390f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obviously, the answer is: 42.\n"
     ]
    }
   ],
   "source": [
    "generator = outlines.generate.regex(\n",
    "    model, \n",
    "    r\"Obviously, the answer is: \\d+\\.\",\n",
    "    sampler=outlines.samplers.greedy(),\n",
    ")\n",
    "\n",
    "output = generator(\n",
    "    prompt, \n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73cdc65-b208-498c-a778-68ccce2a9975",
   "metadata": {},
   "source": [
    "And just to confirm it's not a fluke, we double our sample size to two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b86dc3e7-3973-4023-9aad-69f3174844eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obviously, the answer is: 822.\n"
     ]
    }
   ],
   "source": [
    "output = generator(\n",
    "    \"What is 402 + 420?\", \n",
    "    max_tokens=25,\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f82ffe-60e6-438c-b509-4f98258f1d4d",
   "metadata": {},
   "source": [
    "We now have improved the performance of our LLM and got it to generate text in a way we can easily parse.\n",
    "\n",
    "But what if we could output more complex structured outputs that are even easier to parse? What if we could define the structure in Python, instead of regex? What if we could define a hierarchy of structure? This is where the real strength of Outlines lies. \n",
    "\n",
    "Below, we use the `generate.json` method which takes in a JSON schema of what our output should conform to. JSON schema syntax is a bit convoluted, so lucky for us we can pass a `pydantic.BaseModel` object, which we show how to do below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b16ae1f2-f039-467c-af79-a5345422d24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Schema(left_operand=40, operator=<Operator.ADDITION: 'ADDITION'>, right_operand=2, answer=42)\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Operator(str, enum.Enum):\n",
    "    ADDITION = \"ADDITION\"\n",
    "    SUBTRACTION = \"SUBTRACTION\"\n",
    "    MULTIPLICATION = \"MULTIPLICATION\"\n",
    "    DIVISION = \"DIVISION\"\n",
    "\n",
    "class Schema(pydantic.BaseModel):\n",
    "    left_operand: int\n",
    "    operator: Operator\n",
    "    right_operand: int\n",
    "    answer: int\n",
    "\n",
    "generator = outlines.generate.json(\n",
    "    model,\n",
    "    Schema,\n",
    "    sampler=outlines.samplers.greedy(),\n",
    ")\n",
    "\n",
    "output = generator(\n",
    "    prompt, \n",
    ")\n",
    "\n",
    "repr(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b855ef-6050-4a77-b839-da3a9fee789c",
   "metadata": {},
   "source": [
    "Now, not only do we get the correct answer, we get it as a `Schema` object..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "186a545d-c2d1-4dab-9aff-f93769768516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Schema"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c353a2c-0a74-4089-8689-5d8afb56e15e",
   "metadata": {},
   "source": [
    "...we can get the answer directly from the object..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "746c937d-1f57-4704-a37a-2850efc00b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.operator == Operator.ADDITION == \"ADDITION\", output.answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d78d25-7095-42c3-8a2e-b0f19352b3e3",
   "metadata": {},
   "source": [
    "...and also convert it to a dictionary..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63b2af4d-1b22-400b-9a4f-e41e38a58985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'left_operand': 40,\n",
       " 'operator': <Operator.ADDITION: 'ADDITION'>,\n",
       " 'right_operand': 2,\n",
       " 'answer': 42}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1380f789-ac48-4fc2-ae0c-795f65d5c5a6",
   "metadata": {},
   "source": [
    "...or into a JSON string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19415817-7e11-4c50-a43b-7550d952b507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"left_operand\":40,\"operator\":\"ADDITION\",\"right_operand\":2,\"answer\":42}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e670ef3-7e9b-4e09-847a-80b017d2c456",
   "metadata": {},
   "source": [
    "Another quick example for sentiment classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78f57dc6-0119-41ef-89ea-846a2687bac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Classification(sentiment=<Sentiment.POSITIVE: 'POSITIVE'>, sentiment_score=4)\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Sentiment(str, enum.Enum):\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "\n",
    "class Classification(pydantic.BaseModel):\n",
    "    sentiment: Sentiment\n",
    "    sentiment_score: int\n",
    "\n",
    "prompt = \"The movie was great. I loved it!\"\n",
    "\n",
    "generator = outlines.generate.json(\n",
    "    model,\n",
    "    Classification,\n",
    "    sampler=outlines.samplers.greedy(),\n",
    ")\n",
    "\n",
    "output = generator(\n",
    "    prompt,\n",
    ")\n",
    "\n",
    "repr(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43d327f-9470-4f25-918d-5a26131928fb",
   "metadata": {},
   "source": [
    "Using structured generation is a win-win. Your outputs are trivial to parse instead of handling whatever prefixes your LLM can conjure up; and, you get improved performance as a bonus.\n",
    "\n",
    "Outlines makes it easy to apply structured generation to almost any LLM supported by the transformers library."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
